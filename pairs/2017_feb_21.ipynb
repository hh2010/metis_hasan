{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#A code to run ordinary least squares with associated statistics\n",
    "#Jeremy Kedziora\n",
    "#24 March 2016\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "#import libraries\n",
    "import warnings\n",
    "import numpy as np    #import for arrays\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.optimize import minimize    #import for optimization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define functions\n",
    "def maker(N,n_vars,kind = 'linear'):\n",
    "    \"\"\"A function to generate Monte Carlo linear regression data\"\"\"\n",
    "    x = []    #an empty list to hold the data\n",
    "    y = np.zeros(N)    #an array to hold the dependent variable\n",
    "    b = []    #an empty list to hold the true bs\n",
    "    i = 1\n",
    "    while i <= n_vars:    #loop over the variables we want to create\n",
    "        x_i = np.random.normal(loc = 0.0, scale = 1.0, size = N)    #generate the data\n",
    "        x.append(x_i)    #add it to the list of data\n",
    "        b_i = np.random.normal(loc = 0.0, scale = 1.0)    #draw a random effect for this variable\n",
    "        b.append(b_i)    #add it to the list of effects\n",
    "        y = y + b_i*x_i    #add the variable effect to the dependent variable\n",
    "        i += 1    #index up i\n",
    "    \n",
    "    x.append(np.ones(N))    #and a column of ones for a constant\n",
    "    b_i = np.random.normal(loc = 0.0, scale = 1.0)    #draw a random intercept\n",
    "    b.append(b_i)    #append this intercept to the effects\n",
    "    if kind == 'linear':\n",
    "        y = b_i + y + np.random.normal(loc = 0.0, scale = 1.0, size = N)    #add the normally distributed error term and the intercept\n",
    "    if kind == 'logit':\n",
    "        y = (np.random.uniform(0,1,len(y)) < np.exp(b_i + y)/(1 + np.exp(b_i + y)))*1\n",
    "    return [np.array(x).T,np.array(y),np.array(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OLS_mle(b,X,y):\n",
    "    \"\"\"A function to compute OLS coefficients using MLE\"\"\"\n",
    "    s2 = 1.0#math.exp(b[len(b) - 1])    #exponentiate the variance to ensure that it is positive\n",
    "    xb = X.dot(b)    #compute the means\n",
    "    return -1*sum(-0.5*np.log(s2) - (y - xb)**2/(2*s2))    #return the log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit_mle(b,X,y):\n",
    "    \"\"\"A function to compute logit coefficients using MLE\"\"\"\n",
    "    xb = X.dot(b)    #compute the means\n",
    "    return -1*sum(y*xb - np.log(1+np.exp(xb)))    #return the log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56515772 -0.12758514 -0.00702179  0.08378708]\n",
      "[-0.57259197 -0.11743945 -0.00440701  0.08862368]\n"
     ]
    }
   ],
   "source": [
    "Data = maker(100000,3,kind = 'logit')    #make logit data\n",
    "X = Data[0]    #pull out explanatory variables\n",
    "y = Data[1]    #pull out dependent variable\n",
    "b = Data[2]    #pull out true coefficients\n",
    "\n",
    "b = np.random.uniform(0,1,4)*0.01    #set starting values\n",
    "Coefficients = minimize(logit_mle, x0 = b, args = (X,y), method = 'BFGS').x    #maximize the log-likelihood\n",
    "print(Coefficients)    #print out the coefficients\n",
    "print(Data[2])    #print out the true betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4767515  -0.2237589   0.19042283 -0.44034815]\n",
      "[-0.47207773 -0.2331351   0.18882702 -0.44045565]\n"
     ]
    }
   ],
   "source": [
    "Data = maker(100000,3,kind = 'logit')    #make logit data\n",
    "X = Data[0]    #pull out explanatory variables\n",
    "y = Data[1]    #pull out dependent variable\n",
    "b = Data[2]    #pull out true coefficients\n",
    "\n",
    "b = np.random.uniform(0,1,4)*0.01    #set starting values\n",
    "Coefficients = minimize(logit_mle, x0 = b, args = (X,y), method = 'BFGS').x    #maximize the log-likelihood\n",
    "print(Coefficients)    #print out the coefficients\n",
    "print(Data[2])    #print out the true betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the uploaded MLE_Examples_1 notebook to generate fake logistic data.\n",
    "2. Generate data sets with 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100 features.\n",
    "3. Split each data set into a training set and a test set.\n",
    "4. Use sklearn to apply a decision tree and a random forest model to each training set. \n",
    "5. And then use the trained model to predict in the test set.\n",
    "6. Finally, assess the percent correctly predicted by each model in the test set.\n",
    "7. What happens to the percent correctly predicted as the number of features increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the uploaded MLE_Examples_1 notebook to generate fake logistic data.\n",
    "### 2. Generate data sets with 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data10 = maker(10000,10,kind = 'logit')\n",
    "data20 = maker(10000,20,kind = 'logit')\n",
    "data30 = maker(10000,30,kind = 'logit')\n",
    "data40 = maker(10000,40,kind = 'logit')\n",
    "data50 = maker(10000,50,kind = 'logit')\n",
    "data60 = maker(10000,60,kind = 'logit')\n",
    "data70 = maker(10000,70,kind = 'logit')\n",
    "data80 = maker(10000,80,kind = 'logit')\n",
    "data90 = maker(10000,90,kind = 'logit')\n",
    "data100 = maker(10000,100,kind = 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y10 = data10[1]\n",
    "x10 = data10[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split each data set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X10_train, X10_test, y10_train, y10_test = train_test_split(x10, y10, test_size=0.3, stratify=y10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use sklearn to apply a decision tree and a random forest model to each training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(X10_train, y10_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. And then use the trained model to predict in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y10_pred = forest.predict(X10_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Finally, assess the percent correctly predicted by each model in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.801333333333\n",
      "precision:  0.843525179856\n",
      "recall:  0.807692307692\n",
      "f1 score:  0.825219941349\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", accuracy_score(y10_test, y10_pred))\n",
    "print(\"precision: \", precision_score(y10_test, y10_pred))\n",
    "print(\"recall: \", recall_score(y10_test, y10_pred))\n",
    "print(\"f1 score: \", f1_score(y10_test, y10_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What happens to the percent correctly predicted as the number of features increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.993333333333\n",
      "accuracy 2: 0.994333333333\n",
      "accuracy 3: 0.993\n",
      "accuracy 4: 0.990333333333\n",
      "accuracy 5: 0.990333333333\n",
      "accuracy 6: 0.992\n",
      "accuracy 7: 0.99\n",
      "accuracy 8: 0.991666666667\n",
      "accuracy 9: 0.995333333333\n",
      "accuracy 10: 0.992666666667\n"
     ]
    }
   ],
   "source": [
    "datasets = [data10, data20, data30, data40, data50, data60, data70, data80, data90, data100]\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i in datasets:\n",
    "    X = i[0]\n",
    "    y = i[1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    forest = RandomForestClassifier()\n",
    "    forest.fit(X, y)\n",
    "    y_pred = forest.predict(X_test)\n",
    "    print(\"accuracy\", str(datasets.index(i)+1) + \":\", accuracy_score(y_test, y_pred))\n",
    "#     print(\"precision\", str(datasets.index(i)+1) + \":\", precision_score(y_test, y_pred))\n",
    "#     print(\"recall\", str(datasets.index(i)+1) + \":\", recall_score(y_test, y_pred))\n",
    "#     print(\"f1 score\", str(datasets.index(i)+1) + \":\", f1_score(y_test, y_pred))\n",
    "#     print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
